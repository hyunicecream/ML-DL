{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM-(BreastCancer_DATA).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP5fnCriVJStJG8t/rriZRk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyunicecream/ML-DL/blob/main/SVM_(BreastCancer_DATA).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mglearn\n",
        "import mglearn # 시각화"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhNeakADXwWW",
        "outputId": "65500db5-6339-459d-f1a7-5ccfbf44bf1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mglearn\n",
            "  Downloading mglearn-0.1.9.tar.gz (540 kB)\n",
            "\u001b[?25l\r\u001b[K     |▋                               | 10 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20 kB 21.8 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 30 kB 23.5 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 40 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |███                             | 51 kB 24.6 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 61 kB 26.4 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 71 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 81 kB 25.0 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 92 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |██████                          | 102 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 112 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 122 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 133 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 143 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 153 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 163 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 174 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 184 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 194 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 204 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 215 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 225 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 235 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 245 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 256 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 266 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 276 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 286 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 296 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 307 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 317 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 327 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 337 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 348 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 358 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 368 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 378 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 389 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 399 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 409 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 419 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 430 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 440 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 450 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 460 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 471 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 481 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 491 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 501 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 512 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 522 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 532 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 540 kB 26.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mglearn) (1.19.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mglearn) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from mglearn) (1.0.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from mglearn) (1.1.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from mglearn) (7.1.2)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.7/dist-packages (from mglearn) (0.11.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from mglearn) (2.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from mglearn) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mglearn) (3.0.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mglearn) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mglearn) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->mglearn) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->mglearn) (2018.9)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->mglearn) (3.0.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->mglearn) (1.4.1)\n",
            "Building wheels for collected packages: mglearn\n",
            "  Building wheel for mglearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mglearn: filename=mglearn-0.1.9-py2.py3-none-any.whl size=582637 sha256=5640c5c4ddb048a3b6c476aa76854e7f5b8be38ff49ec6e8817f9229a8c64e4b\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/17/e1/1720d6dcd70187b6b6c3750cb3508798f2b1d57c9d3214b08b\n",
            "Successfully built mglearn\n",
            "Installing collected packages: mglearn\n",
            "Successfully installed mglearn-0.1.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WP3CT0W5Xd4f"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cancer = load_breast_cancer()"
      ],
      "metadata": {
        "id": "eWYZotFmX2UL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cancer.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5mgjO-BaUm5",
        "outputId": "8cf13cd0-cac3-432c-c20f-7647c058c779"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 프레임 만들기\n",
        "df = pd.DataFrame(cancer.data, columns=[cancer.feature_names])\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "WwJzhf-GaYxV",
        "outputId": "bfc16e17-e4c6-4840-9cce-b8c83fecbd6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>1.2560</td>\n",
              "      <td>7.673</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.02891</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2.4630</td>\n",
              "      <td>5.203</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.02423</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1.0750</td>\n",
              "      <td>3.425</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.03731</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>0.7260</td>\n",
              "      <td>1.5950</td>\n",
              "      <td>5.772</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.06158</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1.4280</td>\n",
              "      <td>2.548</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.00466</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    mean radius mean texture  ... worst symmetry worst fractal dimension\n",
              "0         17.99        10.38  ...         0.4601                 0.11890\n",
              "1         20.57        17.77  ...         0.2750                 0.08902\n",
              "2         19.69        21.25  ...         0.3613                 0.08758\n",
              "3         11.42        20.38  ...         0.6638                 0.17300\n",
              "4         20.29        14.34  ...         0.2364                 0.07678\n",
              "..          ...          ...  ...            ...                     ...\n",
              "564       21.56        22.39  ...         0.2060                 0.07115\n",
              "565       20.13        28.25  ...         0.2572                 0.06637\n",
              "566       16.60        28.08  ...         0.2218                 0.07820\n",
              "567       20.60        29.33  ...         0.4087                 0.12400\n",
              "568        7.76        24.54  ...         0.2871                 0.07039\n",
              "\n",
              "[569 rows x 30 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습데이터를 구성한다\n",
        "x_train, x_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size= 0.2)"
      ],
      "metadata": {
        "id": "_dv5ARh5bJoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM으로 학습한다.\n",
        "# model = SVC(kernel='linear') # 직선으로 경계를 찾는다.\n",
        "model = SVC(kernel='rbf', gamma=1.0, C=0.5) # 곡선으로 경계를 찾는다.\n",
        "model.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lohep8XHabfO",
        "outputId": "997aff03-9b04-455b-e14c-86f99bf1b22d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=0.5, gamma=1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"* 학습용 데이터로 측정한 정확도 = %.2f\" % model.score(x_train, y_train))\n",
        "print()\n",
        "print(\"* 시험용 데이터로 측정한 정확도 = %.2f\" % model.score(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIkF2cJrbITU",
        "outputId": "a31ff15a-9334-467b-facb-e1879e82d38e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* 학습용 데이터로 측정한 정확도 = 0.63\n",
            "\n",
            "* 시험용 데이터로 측정한 정확도 = 0.62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 정확도가 너무 낮아 표준화를 해보자\n",
        "# scale = StandardScaler()\n",
        "# scale.fit_transform(cancer['data'])\n",
        "feature_data = StandardScaler().fit_transform(cancer.data)"
      ],
      "metadata": {
        "id": "cxfFCOghbNCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습데이터를 구성한다\n",
        "x_train, x_test, y_train, y_test = train_test_split(feature_data, cancer.target, test_size= 0.2)\n",
        "# SVM으로 학습한다.\n",
        "# model = SVC(kernel='linear') # 직선으로 경계를 찾는다.\n",
        "model = SVC(kernel='rbf', gamma=1.0, C=0.5) # 곡선으로 경계를 찾는다.\n",
        "model.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4Px0OPnbnqM",
        "outputId": "dd7dad41-5db1-4eb3-e8b6-942b5b26e709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=0.5, gamma=1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 나아지긴 했지만 많이 높지는 않다. \n",
        "print(\"* 학습용 데이터로 측정한 정확도 = %.2f\" % model.score(x_train, y_train))\n",
        "print()\n",
        "print(\"* 시험용 데이터로 측정한 정확도 = %.2f\" % model.score(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XB61V0Fibrqh",
        "outputId": "6c3e392d-a52b-4ef2-9802-8004eeae43ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* 학습용 데이터로 측정한 정확도 = 0.64\n",
            "\n",
            "* 시험용 데이터로 측정한 정확도 = 0.61\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Non-Linear SVM***"
      ],
      "metadata": {
        "id": "VCY2JI0qdLJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# gamma와 C의 조합을 바꿔가면서 학습 데이터의 정확도가 최대인 조합을 찾는다\n",
        "optAcc = -999\n",
        "optG = 0\n",
        "optC = 0\n",
        "for gamma in np.arange(0.1, 5.0, 0.1):\n",
        "    for c in np.arange(0.1, 5.0, 0.1):\n",
        "        model = SVC(kernel='rbf', gamma=gamma, C=c)\n",
        "        model.fit(x_train, y_train)\n",
        "        acc = model.score(x_test, y_test)\n",
        "        \n",
        "        if acc > optAcc:\n",
        "            optG = gamma\n",
        "            optC = c\n",
        "            optAcc = acc\n",
        "\n",
        "print('Optimal gamma = %.2f' % optG)\n",
        "print('optimal C = %.2f' % optC)\n",
        "print('optimal Accuracy = %.2f' % optAcc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXmaEr90cFTs",
        "outputId": "ea151f6c-4627-44c6-ff83-3ccf04ef794d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal gamma = 0.10\n",
            "optimal C = 0.50\n",
            "optimal Accuracy = 0.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 최적 조건으로 학습한 결과를 확인한다.\n",
        "model = SVC(kernel='rbf', gamma=optG, C=optC)\n",
        "model.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hdzl5pkdWQZ",
        "outputId": "3f486747-44c7-4359-9bab-37cd82141c3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=0.5, gamma=0.1)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 훨씬 높은 결과를 확인할 수 있다. \n",
        "print(\"* 학습용 데이터로 측정한 정확도 = %.2f\" % model.score(x_train, y_train))\n",
        "print()\n",
        "print(\"* 시험용 데이터로 측정한 정확도 = %.2f\" % model.score(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxfQlqVedwJE",
        "outputId": "5f770421-1d45-417f-be05-579c81791174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* 학습용 데이터로 측정한 정확도 = 0.99\n",
            "\n",
            "* 시험용 데이터로 측정한 정확도 = 0.95\n"
          ]
        }
      ]
    }
  ]
}